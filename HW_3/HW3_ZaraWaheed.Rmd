---
title: "Homework 3"
author: "Zara Waheed"
output: 
  pdf_document: 
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load("bayesplot","knitr","arm","ggplot2","rstanarm")
```


## Disclaimer

A few things to keep in mind :
1) Use set.seed() to make sure that the document produces the same random simulation as when you ran the code.
2) Use refresh=0 for any stan_glm() or stan-based model. lm() or non-stan models don't need this!
3) You can type outside of the r chunks and make new r chunks where it's convenient. Make sure it's clear which questions you're answering.
4) Even if you're not too confident, please try giving an answer to the text responses!
5) Please don't print data in the document unless the question asks. It's good for you to do it to look at the data, but not as good for someone trying to read the document later on.
6) Check your document before submitting! Please put your name where "name" is by the author!

## 4.1 Comparison of proportions
A randomized experiment is performed within a survey. 1000  people are contacted. Half the people contacted are promised a $5 incentive to participate, and  half are not promised an incentive. The result is a 50% response rate among the treated group  and 40% response rate among the control group. Give an estimate and standard error of the  average treatment effect. 

```{r}
# Compute standard errors treatment groups
SE_TE = sqrt(0.5^2/500 + 0.5^2/500) 
SE_TE

#estimate of the average treatment effect
Avg_TE <- 0.5 - 0.4
Avg_TE
```

## 4.2 Choosing sample size
You are designing a survey to estimate the gender gap: the difference in  support for a candidate among men and women. Assuming the respondents are a simple random  sample of the voting population, how many people do you need to poll so that the standard error is less than 5 percentage points? 


```{r}
# using sqrt(pˆ(1 − pˆ)/n) we compute n for 5% standard error

se <- 0.05

# Solve the standard error equation and equal it to 0.05
# Rearrange the equation to solve for n

n <- 0.5*(1-0.5)/0.05^2
n

```
The sample size needs to be greater than 100 for a standard error less than 0.05.

## 4.4 Designing an experiment
You want to gather data to determine which of two students is a  better basketball shooter. You plan to have each student take N shots and then compare their  shooting percentages. Roughly how large does N have to be for you to have a good chance of  distinguishing a 30% shooter from a 40% shooter? 

```{r}
# using p1*(1-p1)+p2*(1-p2)*(z/e)^2
# We can assume a standard error of 0.05

p1 <- 0.3
p2 <- 0.4
z <- 1.96 # for 95% confidence interval
e <- 0.05 # standard error
N <- (p1*(1-p1)+p2*(1-p2))*((z/e)^2)
```


## 4.6 Hypothesis testing
The following are the proportions of girl births in Vienna for each month in  Girl births 1908 and 1909 (out of an average of 3900 births per month):

```{r}
birthdata <- c(.4777,.4875,.4859,.4754,.4874,.4864,.4813,.4787,.4895,.4797,.4876,.4859,
               .4857,.4907,.5010,.4903,.4860,.4911,.4871,.4725,.4822,.4870,.4823,.4973)
```

The data are in the folder Girls. These proportions were used by von Mises (1957) to support  a claim that that the sex ratios were less variable than would be expected under the binomial  distribution. We think von Mises was mistaken in that he did not account for the possibility that  this discrepancy could arise just by chance.  

### (a) Compute the standard deviation of these proportions and compare to the standard deviation  that would be expected if the sexes of babies were independently decided with a constant  probability over the 24-month period.  

```{r}
# standard deviation od birthdata
sd_1 <- sd(birthdata)
sd_1

# standard deviation for independant 100 samples and then get the average with 0.5 as the constant probability
set.seed(123)
sample <- rbinom(24, 100, 0.5)
sd_2 <- sd(sample)/100
sd_2

# Compare the two by taking the difference
sd_1-sd_2

hist(sample)
```
We can see that the difference between the sd of these two situations is very small.

### (b) The observed standard deviation of the 24 proportions will not be identical to its theoretical  expectation. In this case, is this difference small enough to be explained by random variation?  Under the randomness model, the actual variance should have a distribution with expected  value equal to the theoretical variance, and proportional to a chi-square random variable with 23  degrees of freedom; see page 53. 

```{r}
mod_4.6b <- rep(NA, 100)

set.seed(123)
for(i in 1:100)
  mod_4.6b[i] = sd(rbinom(24,3900,mean(birthdata))/3900)

hist(mod_4.6b)
abline(v=sd_1, col = 'red')
```
The difference is small enough to be explained by random variation since it's a very small difference.

## 5.5 Distribution of averages and differences
The heights of men in the United States are approximately  normally distributed with mean 69.1 inches and standard deviation 2.9 inches. The heights of  women are approximately normally distributed with mean 63.7 inches and standard deviation  2.7 inches. Let x be the average height of 100 randomly sampled men, and y be the average  height of 100 randomly sampled women. In R, create 1000 simulations of x - y and plot their  histogram. Using the simulations, compute the mean and standard deviation of the distribution  of x - y and compare to their exact values. 

```{r}
sim_heights <- c(1:1000)
men_height <- 69.1
women_height <- 63.7

set.seed(123)
for (i in 1:1000){ 
x <- rnorm(100, 69.1, 2.9)
y <- rnorm(100, 63.7, 2.7)
mx <- mean(x)
my <- mean(y)
sim_heights[i] <- mx-my
}

sim_sd <- sd(sim_heights)
sim_sd

real_mean <- men_height - women_height
sim_mean <- mean(sim_heights)
sim_mean
real_mean

```
The simulated sd is greater than the real sd, which would be an accurate estimate when we account for additional uncertainty due to the simulations. The mean of the simulations is very close to the actual mean.

## 5.6 Propagation of uncertainty: 
We use a highly idealized setting to illustrate the use of simulations  in combining uncertainties. Suppose a company changes its technology for widget production,  and a study estimates the cost savings at 5 dollars per unit, but with a standard error of 4 dollars. Furthermore,  a forecast estimates the size of the market (that is, the number of widgets that will be sold)  at 40 000, with a standard error of 10 000. Assuming these two sources of uncertainty are  independent, use simulation to estimate the total amount of money saved by the new product  (that is, savings per unit, multiplied by size of the market). 

```{r}
ms <- rep(NA,100)

set.seed(123)
for(i in 1:100){
  quantity <- rnorm(1,40000,10000)
  savings <- rnorm(1,5,4)
  ms[i] <- quantity*savings
}

moneysaved <- mean(ms)
moneysaved
```
On average, 190722 is the money saved by the new product.

## 5.8 Coverage of confidence intervals: 
On page 15 there is a discussion of an experimental study of  an education-related intervention in Jamaica, in which the point estimate of the treatment effect,  on the log scale, was 0.35 with a standard error of 0.17. Suppose the true effect is 0.10—this  seems more realistic than the point estimate of 0.35—so that the treatment on average would  increase earnings by 0.10 on the log scale. Use simulation to study the statistical properties of  this experiment, assuming the standard error is 0.17.  

### (a) Simulate 1000 independent replications of the experiment assuming that the point estimate is  normally distributed with mean 0.10 and standard deviation 0.17.  

```{r}
sim <- rep(NA,1000)

set.seed(123)
for (i in 1:1000) {
  exp <- rnorm(127, 0.1, 0.17)
  sim[i] <- mean(exp)
}

summary(sim)
```

### (b) For each replication, compute the 95% confidence interval. Check how many of these intervals  include the true parameter value.  

```{r}
sim <- rep(NA,1000)
cf <- rep(NA,1000)
cf0 <- rep(NA,1000)

set.seed(123)
for (i in 1:1000) {
  exp <- rnorm(127, 0.1, 0.17)
  ll <- mean(exp)+qt(0.025,100)*sd(exp)/sqrt(101)
  ul <- mean(exp)+qt(0.975,100)*sd(exp)/sqrt(101)

  sim[i] <- mean(exp)
  cf[i] <- ifelse(ll<0.1&ul>0.1,1,0)
  cf0[i] <- ifelse(ll<0&ul>0,mean(exp),0)
}

summary(sim)
sum(cf)
```
969 of these values contain the true value

### (c) Compute the average and standard deviation of the 1000 point estimates; these represent the  mean and standard deviation of the sampling distribution of the estimated treatment effect. 

```{r}
mean(exp)
sd(exp)
```

## 5.9 Coverage of confidence intervals after selection on statistical significance: 
Take your 1000  simulations from Exercise 5.8, and select just the ones where the estimate is statistically  significantly different from zero. Compute the average and standard deviation of the selected  point estimates. Compare these to the result from Exercise 5.8. 

```{r}
stat_sig <- ifelse(cf0==0,0,cf0)

mean(stat_sig)
sd(stat_sig)
```

## 9.8 Simulation for decision analysis: 
An experiment is performed to measure the efficacy of a  television advertising program. The result is an estimate that each minute spent on a national  advertising program will increase sales by 500,000 dollars, and this estimate has a standard error of  200000 dollars. Assume the uncertainty in the treatment effect can be approximated by a normal  distribution. Suppose ads cost 300000 dollars per minute. What is the expected net gain for purchasing  20 minutes of ads? What is the probability that the net gain is negative? 

```{r}

ad_cost = 300000*20

net_gain= rep(NA,1000)

set.seed(123)
for(i in 1:1000){
  #value for each minute the add runs
  value_per_min <- rnorm(20, 500000, 200000)
  net_gain[i] <- sum(value_per_min) - ad_cost
}

net_gain = rnorm(20, 500000, 200000) - ad_cost

hist(net_gain)
```
From our results, it seems that the chance of a net gain being negative is not very high.

## 10.3 Checking statistical significance: 
In this exercise and the next, you will simulate two variables  that are statistically independent of each other to see what happens when we run a regression to  predict one from the other. Generate 1000 data points from a normal distribution with mean 0  and standard deviation 1 by typing var1 <- rnorm(1000,0,1) in R. Generate another variable  in the same way (call it var2). Run a regression of one variable on the other. Is the slope  coefficient “statistically significant”? We do not recommend summarizing regressions in this  way, but it can be useful to understand how this works, given that others will do so. 

```{r}
set.seed(123)

var1 <- rnorm(1000,0,1)
var2 <- rnorm(1000,0,1)
fit_10.3 <- stan_glm(var2~var1, refresh = 0)
summary(fit_10.3)
```
The slope coefficient is not statistically significant but, in an actual example, we won't disregard the variable as it can still give us some information about the variable.
There does not seem to be any effect of var1 on var2.

## 10.4 Simulation study of statistical significance: 
Continuing the previous exercise, run a simulation  repeating this process 100 times. This can be done using a loop. From each simulation, save the  z-score (the estimated coefficient of var1 divided by its standard error). If the absolute value of  the z-score exceeds 2, the estimate is “statistically significant.”  To perform this computation, we start by creating an empty vector of z-scores filled with missing values (NAs). Another approach is to start with z_scores <- numeric(length=100), which  would set up a vector of zeroes. In general, however, we prefer to initialize with NAs, because  then when there is a bug in the code, it sometimes shows up as NAs in the final results, alerting  us to the problem. 

How many of these 100 z-scores exceed 2 in absolute value, thus achieving the conventional  level of statistical significance? 

Here is code to perform the simulation:

This chunk will have eval=FALSE. If you want it to run, please copy it to a new chunk, or remove eval=FALSE!

```{r}
z_scores <- rep(NA,100)

set.seed(123)
for(i in 1:100) {
  var1 <- rnorm(1000,0,1)
  var2 <- rnorm(1000,0,1)
  fake <- data.frame(var1,var2)
  fit <- stan_glm(var2 ~ var1,data=fake,refresh=0)
  z_scores[i] <- coef(fit)[2] / se(fit)[2]
}
```

```{r}
zs <- data.frame(z_scores)
stat_significant <- subset(zs, zs > 2 & zs < -2)
length(stat_significant)
```
Only 1 value exceeds 2 in absolute value.

## 11.3 Coverage of confidence intervals: 
Consider the following procedure:  

- Set n = 100 and draw n continuous values xi uniformly distributed between 0 and 10. Then  simulate data from the model yi = a + bxi + errori, for i = 1,..., n, with a = 2, b = 3, and  independent errors from a normal distribution.  

- Regress y on x. Look at the median and mad sd of b. Check to see if the interval formed by  the median ± 2 mad sd includes the true value, b = 3.  

- Repeat the above two steps 1000 times.  

### (a) True or false: the interval should contain the true value approximately 950 times. Explain  your answer. 

```{r}
ci1 <-rep(NA, 1000)

set.seed(123)
for (i in 1:1000) {
n = 100
x <- runif(100, 0, 10)
y = 2 + 3*x + rnorm(100, 0, 2)
fit_11.3a <- lm(y ~ x)

ll <- summary(fit_11.3a)$coefficients[2,1] - 2*summary(fit_11.3a)$coefficients[2,2]
ul <- summary(fit_11.3a)$coefficients[2,1] + 2*summary(fit_11.3a)$coefficients[2,2]
ci1[i] <- ifelse(ll<3&ul>3, 1,0)
}

mean(ci1)
```
True. The mean and se from 'lm' will give a good approximate to the median and mad sd from 'stan_glm' and makes it easier to use the coefficient function. The interval seems to contain the true value approximately 950 times or more.

### (b) Same as above, except the error distribution is bimodal, not normal. True or false: the  interval should contain the true value approximately 950 times. Explain your answer. 

```{r}
ci2 <-rep(NA, 1000)

set.seed(123)

for (i in 1:1000) {
  
x <- runif(100, 0, 10)
y = 2 + 3*x + rbinom(100, 1, 0.3)
fit_11.3b <- lm(y ~ x)

ll <- summary(fit_11.3b)$coefficients[2,1] - 2*summary(fit_11.3b)$coefficients[2,2]
ul <- summary(fit_11.3b)$coefficients[2,1] + 2*summary(fit_11.3b)$coefficients[2,2]
ci2[i] <- ifelse(ll<3&ul>3, 1,0)
}

mean(ci2)
```
False but close. The interval contains almost the true value less than but almost 950 of the times. However, the value is less than 950 in every trial.
